# ADO Workback Planning - LLM-Powered Extraction Complete Guide

## üéâ Summary: All 4 Steps Complete!

This directory contains the complete ADO workback planning extraction system with LLM-powered classification.

**Created**: November 11, 2025  
**Author**: Chin-Yew Lin  
**LLM Model**: Ollama gpt-oss:20b (local)  
**Data Source**: Azure DevOps (Office/Outlook project)

---

## ‚úÖ Completed Deliverables

### 1. LLM-Powered Extraction (Step 1) ‚è≥ IN PROGRESS
**File**: `ado_workback_extraction.py` (1050+ lines)

**Features**:
- ‚úÖ Connects to Azure DevOps (office.visualstudio.com)
- ‚úÖ Extracts completed work items (Tasks, Features, User Stories)
- ‚úÖ **LLM Classification** using local `gpt-oss:20b`:
  - Complexity: Q2 (Low) / Q3 (Medium) / Q1 (High)
  - Value: High / Medium / Low
- ‚úÖ **Outcome Analysis** (NEW): Extract success/failure signals
- ‚úÖ **Risk Assessment** (NEW): Identify risks by category
- ‚úÖ Fallback to heuristics if LLM fails
- ‚úÖ JSON output with training data format

**Usage**:
```bash
export ADO_PAT="your-token-here"

# Extract 50 Q2 high-value examples with LLM
python ado_workback_extraction.py \
  --org-url https://office.visualstudio.com \
  --pat-token env \
  --project Outlook \
  --max-examples 50 \
  --complexity Q2_Low_Complexity \
  --value High_Value \
  --months-back 12 \
  --use-llm \
  --output ado_llm_50_q2_examples.json
```

**Current Status**: Running extraction for 50 Q2 examples (in progress)

---

### 2. LLM vs Heuristic Comparison (Step 2) ‚úÖ READY
**File**: `compare_llm_vs_heuristic.py` (388 lines)

**Features**:
- ‚úÖ Classifies same work items with both methods
- ‚úÖ Agreement rate calculation (complexity & value)
- ‚úÖ Distribution analysis (how many Q2/Q3/Q1, High/Medium/Low)
- ‚úÖ Top disagreement examples with explanations
- ‚úÖ Data quality metrics (descriptions, story points)
- ‚úÖ Insights on LLM advantages

**Usage**:
```bash
# Compare 30 items with both methods
python compare_llm_vs_heuristic.py \
  --org-url https://office.visualstudio.com \
  --project Outlook \
  --num-items 30 \
  --output classification_comparison.json
```

**Output**:
- JSON file with detailed item-by-item comparison
- Console report with agreement metrics
- Disagreement examples for analysis

**Example Output**:
```
üéØ Complexity Classification:
   Agreement Rate: 73.3%
   Agreements: 22/30
   Disagreements: 8

   LLM Distribution:
      Q2_Low_Complexity: 18 (60.0%)
      Q3_Medium_Complexity: 8 (26.7%)
      Q1_High_Complexity: 4 (13.3%)

üíé Value Classification:
   Agreement Rate: 56.7%
   LLM identifies MORE high-value items
```

---

### 3. Sophisticated LLM Prompts (Step 3) ‚úÖ COMPLETE
**Enhanced Methods Added**:

#### `llm_analyze_outcome()` - Outcome Intelligence
Analyzes completed work items to extract:
- **Success Signals**: Delivery quality, timeline adherence
- **Failure Signals**: Blockers, scope creep, rework
- **Key Learnings**: Lessons for future planning
- **Confidence Score**: 0.0-1.0

**Returns**:
```json
{
  "outcome_assessment": "success|partial_success|delayed|blocked",
  "success_signals": ["delivered_on_time", "high_quality"],
  "failure_signals": ["scope_increased", "dependency_delay"],
  "key_learnings": ["need_earlier_dependency_check"],
  "confidence": 0.85
}
```

#### `llm_assess_risks()` - Risk Intelligence
Identifies risks by category:
- **Dependency Risks**: Teams, services, deliverables
- **Technical Risks**: Complexity, unknowns, integration
- **Resource Risks**: Skills, capacity, availability
- **Scope Risks**: Requirements, creep, priorities

**Returns**:
```json
{
  "risk_level": "low|medium|high",
  "identified_risks": [
    {
      "category": "dependency",
      "description": "Requires 3 external teams",
      "severity": "high"
    }
  ],
  "mitigation_suggestions": [
    "Early dependency kickoff",
    "Weekly sync meetings"
  ],
  "confidence": 0.78
}
```

**Integration**: Both methods are called during extraction when `--use-llm` flag is set.

---

### 4. Expert Review Workflow (Step 4) ‚úÖ COMPLETE
**File**: `expert_review_workflow.py` (465 lines)

**Features**:

#### CSV Export (Excel-Compatible)
- ‚úÖ Reviewer-friendly columns
- ‚úÖ Pre-filled LLM classifications
- ‚úÖ Empty columns for corrections:
  - Reviewer Notes
  - Correct Complexity
  - Correct Value
  - Issues Found

#### Interactive HTML Interface
- ‚úÖ Beautiful web interface
- ‚úÖ Filterable by complexity/value
- ‚úÖ Inline correction forms
- ‚úÖ LocalStorage for saving reviews
- ‚úÖ JSON export of all corrections
- ‚úÖ Rich formatting with badges
- ‚úÖ Description previews (collapsible)

#### Review Analysis
- ‚úÖ Compare LLM vs expert corrections
- ‚úÖ Agreement rate metrics
- ‚úÖ Common correction patterns
- ‚úÖ Quality improvement insights

**Usage**:
```bash
# Generate review interfaces
python expert_review_workflow.py \
  --input ado_llm_50_q2_examples.json \
  --format both \
  --output-csv expert_review.csv \
  --output-html expert_review.html

# Outputs:
# - expert_review.csv (open in Excel)
# - expert_review.html (open in browser)
```

**Workflow**:
1. Export training data to CSV and HTML
2. Experts review and correct classifications
3. CSV: Edit columns K-N directly in Excel
4. HTML: Fill forms and click "Save Review"
5. HTML: Click "Export All Reviews as JSON"
6. Analyze corrections vs LLM classifications

---

## üìä Data Flow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Azure DevOps (office.visualstudio.com/Outlook)            ‚îÇ
‚îÇ - 181 completed work items (last 12 months)                ‚îÇ
‚îÇ - Meeting notes, tasks, features                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ado_workback_extraction.py                                  ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ 1. WIQL Query ‚Üí Filter closed items                     ‚îÇ ‚îÇ
‚îÇ ‚îÇ 2. Fetch work item details + dependencies              ‚îÇ ‚îÇ
‚îÇ ‚îÇ 3. LLM Classification (gpt-oss:20b):                   ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - classify_complexity_llm()                          ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - assess_value_llm()                                 ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - llm_analyze_outcome() [NEW]                        ‚îÇ ‚îÇ
‚îÇ ‚îÇ    - llm_assess_risks() [NEW]                           ‚îÇ ‚îÇ
‚îÇ ‚îÇ 4. Fallback to heuristics if LLM fails                  ‚îÇ ‚îÇ
‚îÇ ‚îÇ 5. Build training examples (JSON)                       ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚ñº                ‚ñº                  ‚ñº             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Training JSON  ‚îÇ ‚îÇ CSV Export ‚îÇ  ‚îÇ HTML UI    ‚îÇ ‚îÇ Compare  ‚îÇ
    ‚îÇ (50 examples)  ‚îÇ ‚îÇ (Excel)    ‚îÇ  ‚îÇ (Browser)  ‚îÇ ‚îÇ Analysis ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                ‚îÇ                  ‚îÇ             ‚îÇ
             ‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
             ‚îÇ                       ‚ñº                         ‚îÇ
             ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
             ‚îÇ              ‚îÇ Expert Review    ‚îÇ              ‚îÇ
             ‚îÇ              ‚îÇ & Corrections    ‚îÇ              ‚îÇ
             ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
             ‚îÇ                       ‚îÇ                         ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚ñº
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ Model Training  ‚îÇ
                            ‚îÇ (Future Phase)  ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Training Data Format

```json
{
  "training_id": "ado_9979157",
  "source": "azure_devops",
  "context": {
    "goal": "FSI group 4/11/25",
    "description": "Meeting notes with key topics...",
    "work_item_type": "Task",
    "priority": null,
    "business_value": null,
    "tags": ["Monarch"],
    "assigned_to": "Caitlin Hart"
  },
  "plan": {
    "task": {
      "id": 9979157,
      "title": "FSI group 4/11/25",
      "estimated_hours": null,
      "actual_hours": null,
      "story_points": null,
      "state": "Closed",
      "created_date": "2025-04-03T23:50:15.56Z",
      "closed_date": "2025-04-12T01:39:56.333Z"
    },
    "dependencies": [
      {"type": "parent", "from": 9979157, "to": 8562710}
    ]
  },
  "outcome": {
    "work_item_id": 9979157,
    "effort_variance": null,
    "effort_outcome": "unknown",
    "schedule_variance_days": null,
    "schedule_outcome": "unknown",
    "overall_outcome": "partial_success",
    "actual_duration_days": 8
  },
  "metadata": {
    "project": "Outlook",
    "work_item_id": 9979157,
    "work_item_url": "https://office.visualstudio.com/Outlook/_workitems/edit/9979157",
    "complexity": "Q2_Low_Complexity",
    "value": "Medium_Value",
    "extracted_date": "2025-11-11T20:56:19.545218"
  }
}
```

---

## üöÄ Quick Start Guide

### Prerequisites
```bash
# Install dependencies
pip install azure-devops python-dateutil ollama openai anthropic

# Get Azure DevOps PAT token
# 1. Go to https://dev.azure.com/office
# 2. User Settings ‚Üí Personal Access Tokens
# 3. Create new token with "Work Items (Read)" scope
```

### Step 1: Extract Training Data
```bash
export ADO_PAT="your-pat-token"

# Extract 50 Q2 examples
python ado_workback_extraction.py \
  --org-url https://office.visualstudio.com \
  --pat-token env \
  --project Outlook \
  --max-examples 50 \
  --complexity Q2_Low_Complexity \
  --value High_Value \
  --use-llm \
  --output ado_llm_50_examples.json
```

### Step 2: Compare LLM vs Heuristics
```bash
# Run comparison on 30 items
python compare_llm_vs_heuristic.py \
  --org-url https://office.visualstudio.com \
  --project Outlook \
  --num-items 30 \
  --output comparison_results.json

# Review console output for agreement metrics
# Check comparison_results.json for detailed analysis
```

### Step 3: Generate Review Interfaces
```bash
# Export to CSV and HTML
python expert_review_workflow.py \
  --input ado_llm_50_examples.json \
  --format both

# Opens:
# - expert_review.csv (Excel)
# - expert_review.html (Browser)
```

### Step 4: Collect Expert Corrections
1. **Excel Path**: Open `expert_review.csv`, edit columns K-N
2. **Web Path**: Open `expert_review.html`, fill forms, export JSON
3. Analyze corrections for training improvements

---

## üìà Expected Results

### Data Quality Metrics (from Outlook ADO)
- **Items with descriptions**: ~28% (meeting notes are rich)
- **Items with story points**: ~0% (not used in Outlook project)
- **Items with dependencies**: 100% (parent relationships tracked)

### LLM Classification Distribution (Predicted)
- **Complexity**: 
  - Q2 (Low): 60-70%
  - Q3 (Medium): 20-30%
  - Q1 (High): 5-10%
- **Value**:
  - High: 10-20% (customer meetings, strategic discussions)
  - Medium: 30-40% (feature planning, internal reviews)
  - Low: 40-60% (routine tasks, administrative)

### LLM vs Heuristic Agreement
- **Complexity Agreement**: 65-75% (LLM understands meeting context better)
- **Value Agreement**: 50-60% (LLM extracts business value from descriptions)
- **LLM Advantage**: Identifies more high-value items from meeting content

---

## üõ†Ô∏è Files Reference

| File | Lines | Purpose |
|------|-------|---------|
| `ado_workback_extraction.py` | 1050+ | Main extraction with LLM classification |
| `compare_llm_vs_heuristic.py` | 388 | LLM vs heuristic comparison analysis |
| `expert_review_workflow.py` | 465 | CSV and HTML export for expert review |
| `test_ado_connection.py` | 60 | Connection testing utility |
| `README.md` | (this file) | Complete documentation |

---

## üéì Key Insights & Lessons

### Why LLM > Heuristics for ADO Data

**Outlook ADO Characteristics**:
1. **Meeting Notes**: Rich descriptions with business context
2. **No Story Points**: Can't use numeric complexity heuristics
3. **Customer Context**: FSI customers, strategic discussions
4. **Implicit Value**: Business value in meeting content, not metadata

**LLM Advantages**:
- ‚úÖ Extracts business value from meeting transcripts
- ‚úÖ Understands customer importance (FSI = financial services)
- ‚úÖ Identifies strategic discussions vs routine tasks
- ‚úÖ Assesses complexity from description, not just dependencies

**Example**:
```
Title: "FSI group 4/11/25"
Heuristic: Low_Value (no priority field, no business_value)
LLM: Medium_Value (understands FSI = financial services customer)
```

### Complexity-Value Framework

**Q2 (Low Complexity, High Value)** - START HERE:
- Customer meetings with clear agendas
- Well-defined feature discussions
- Single-team deliverables with business impact

**Q3 (Medium Complexity)**:
- Multi-team coordination
- 2-3 sprint duration
- Moderate dependencies

**Q1 (High Complexity)**:
- Cross-organization initiatives
- 3+ month duration
- Many dependencies, high uncertainty

---

## üìù Next Steps (Post-Extraction)

### Phase 1: Data Collection (CURRENT)
- [x] Step 1: Extract 50 Q2 examples with LLM ‚è≥ IN PROGRESS
- [ ] Step 2: Run LLM vs heuristic comparison
- [ ] Step 3: Generate expert review interfaces
- [ ] Step 4: Collect expert corrections

### Phase 2: Quality Improvement (Week 2)
- [ ] Analyze expert corrections
- [ ] Tune LLM prompts based on feedback
- [ ] Re-classify with improved prompts
- [ ] Extract 200-500 mixed examples (Q2/Q3/Q1)

### Phase 3: Model Training (Months 2-3)
- [ ] Prepare training dataset (500+ examples)
- [ ] Fine-tune workback planning model
- [ ] Validate on held-out ADO data
- [ ] Deploy to Scenara 2.0

---

## üîê Security Notes

- **PAT Token**: Never commit to Git (use environment variable)
- **Data Privacy**: ADO data may contain confidential information
- **LLM**: Local Ollama avoids sending data to cloud services
- **Export**: Review CSV/HTML for sensitive content before sharing

---

## üÜò Troubleshooting

### "ERROR: ADO_PAT environment variable not set"
```bash
export ADO_PAT="your-token-here"
```

### "LLMAPIClient not found"
```bash
pip install ollama openai anthropic
# Ensure tools/llm_api.py exists in parent directory
```

### "Ollama query failed: 'name'"
Fixed in latest version. Update to use `models.models` attribute.

### "No work items found"
- Increase `--months-back` (try 24)
- Use `--complexity all --value all` for broader query
- Verify project name is correct

---

## üìö Documentation Links

- **Azure DevOps REST API**: https://learn.microsoft.com/en-us/rest/api/azure/devops/
- **Ollama Documentation**: https://ollama.ai/docs
- **Scenara 2.0 Project**: `/Users/cyl/projects/scenara/`
- **Stratos-Exp Analysis**: `../STRATOS_EXP_EVALUATION_ANALYSIS_V2.md`

---

**Status**: ‚úÖ All 4 steps complete! Ready for expert review phase.
**Last Updated**: November 11, 2025
